import shutil
import yaml
from typing import List
from pyspark.sql import DataFrame
from consumerComplaint.logger import logging
from consumerComplaint.exception import ConsumerComplaintException
import os, sys
from pyspark.ml.evaluation import MulticlassClassificationEvaluator


def write_yaml_file(file_path: str, data: dict = None):
    """
    Create yaml file 
    file_path: str
    data: dict
    """
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, "w") as yaml_file:
            if data is not None:
                yaml.dump(data, yaml_file)
    except Exception as e:
        raise ConsumerComplaintException(e, sys)


def read_yaml_file(file_path: str) -> dict:
    """
    Reads a YAML file and returns the contents as a dictionary.
    file_path: str
    """
    try:
        with open(file_path, 'rb') as yaml_file:
            return yaml.safe_load(yaml_file)
    except Exception as e:
        raise ConsumerComplaintException(e, sys) from e
